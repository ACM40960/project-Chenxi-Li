{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f4e802-e9c9-4053-8b49-1e03e5110c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from colorama import Fore, Style, init\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_auc_score, roc_curve, auc\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Initialize colorama for colored terminal output\n",
    "init(autoreset=True)\n",
    "\n",
    "# Function to load data\n",
    "def load_data(directory, label):\n",
    "    filepaths = []\n",
    "    labels = []\n",
    "    for file in os.listdir(directory):\n",
    "        filepaths.append(os.path.join(directory, file))  # Get full file path\n",
    "        labels.append(label)  # Assign label to each file\n",
    "    return filepaths, labels\n",
    "\n",
    "# Specify directories containing \"black bear\" and \"newfoundland\" images\n",
    "black_bear_dir = \"black bear\"\n",
    "newfoundland_dir = \"newfoundland\"\n",
    "\n",
    "# Load data from directories\n",
    "black_bear_files, black_bear_labels = load_data(black_bear_dir, 'black bear')\n",
    "newfoundland_files, newfoundland_labels = load_data(newfoundland_dir, 'newfoundland')\n",
    "\n",
    "# Combine data into a single DataFrame\n",
    "filepaths = black_bear_files + newfoundland_files\n",
    "labels = black_bear_labels + newfoundland_labels\n",
    "df = pd.DataFrame({'filepath': filepaths, 'label': labels})\n",
    "\n",
    "# Split data into train, validation, and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, stratify=df['label'], random_state=42)\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify=train_df['label'], random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e29d37-b0d7-44e9-acf5-84b8cafc1ee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create data generators\n",
    "def create_generators(train_df, val_df, test_df, img_size=(224, 224), batch_size=32):\n",
    "    # ImageDataGenerator for training with rescaling\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    # ImageDataGenerator for validation and testing with rescaling\n",
    "    val_test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Training data generator\n",
    "    train_generator = train_datagen.flow_from_dataframe(\n",
    "        train_df,\n",
    "        x_col='filepath',\n",
    "        y_col='label',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # Validation data generator\n",
    "    val_generator = val_test_datagen.flow_from_dataframe(\n",
    "        val_df,\n",
    "        x_col='filepath',\n",
    "        y_col='label',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    # Test data generator\n",
    "    test_generator = val_test_datagen.flow_from_dataframe(\n",
    "        test_df,\n",
    "        x_col='filepath',\n",
    "        y_col='label',\n",
    "        target_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode='categorical',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    return train_generator, val_generator, test_generator\n",
    "\n",
    "# Create data generators\n",
    "train_generator, val_generator, test_generator = create_generators(train_df, val_df, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865adb51-c822-4758-a7b5-8eabb66a6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build the model\n",
    "def build_model(base_model, num_classes, dropout_rate=0.25):\n",
    "    model = Sequential([\n",
    "        base_model,  # Base model (DenseNet121)\n",
    "        BatchNormalization(),  # Add batch normalization layer\n",
    "        Dropout(dropout_rate),  # Add dropout layer\n",
    "        Flatten(),  # Flatten the output\n",
    "        Dense(128, activation='relu'),  # Fully connected layer with 128 units\n",
    "        Dropout(dropout_rate),  # Add dropout layer\n",
    "        Dense(num_classes, activation='softmax')  # Output layer with softmax activation\n",
    "    ])\n",
    "    model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load the base model\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False  # Freeze the base model layers\n",
    "num_classes = len(train_generator.class_indices)  # Number of classes\n",
    "model = build_model(base_model, num_classes)  # Build the model\n",
    "\n",
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb20c88-fac5-4527-92db-ffe765cdbca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)  # Early stopping callback\n",
    "\n",
    "# Fit the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=15,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb89d835-6897-446b-9998-b2fbc15fe53b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "validation_loss, validation_accuracy = model.evaluate(val_generator)\n",
    "print(\"Validation Loss:\", validation_loss)\n",
    "print(\"Validation Accuracy:\", validation_accuracy)\n",
    "\n",
    "# Save the model\n",
    "model.save('model/my_model.h5')\n",
    "print(\"Model saved to 'model/my_model.h5'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b86c25-8524-45b7-a094-29f124cb9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot training history\n",
    "def plot_training_history(history):\n",
    "    acc = history.history['accuracy']  # Training accuracy\n",
    "    val_acc = history.history['val_accuracy']  # Validation accuracy\n",
    "    loss = history.history['loss']  # Training loss\n",
    "    val_loss = history.history['val_loss']  # Validation loss\n",
    "    epochs = range(len(acc))  # Number of epochs\n",
    "\n",
    "    plt.figure(figsize=(14, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "    plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "    plt.title('Training and validation loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.savefig('training_history.png')  # Save as image\n",
    "    plt.show()\n",
    "\n",
    "# Plot training history\n",
    "plot_training_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e19943-dc3d-4f7d-a125-4a18f09b7d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize images\n",
    "def visualize_images(generator, num_images=20):\n",
    "    images, labels = next(generator)  # Get a batch of images and labels\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    for i in range(num_images):\n",
    "        plt.subplot(5, 4, i + 1)\n",
    "        plt.imshow(images[i])  # Display image\n",
    "        class_label = labels[i].argmax()  # Get class label\n",
    "        class_name = list(generator.class_indices.keys())[list(generator.class_indices.values()).index(class_label)]  # Get class name\n",
    "        plt.title(class_name)  # Set title as class name\n",
    "        plt.axis('off')\n",
    "    plt.savefig('visualize_images.png')  # Save as image\n",
    "    plt.show()\n",
    "\n",
    "# Visualize images from the training set\n",
    "visualize_images(train_generator)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b158f-5685-46f9-b7f6-0728fae1a87b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot confusion matrix\n",
    "def plot_confusion_matrix(cm, class_names):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=class_names, yticklabels=class_names)  # Plot heatmap\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('Actual')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.savefig('confusion_matrix.png')  # Save as image\n",
    "    plt.show()\n",
    "\n",
    "# Plot confusion matrix\n",
    "y_pred = model.predict(test_generator)  # Predict on test data\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)  # Get predicted classes\n",
    "y_true = test_generator.classes  # True classes\n",
    "cm = confusion_matrix(y_true, y_pred_classes)  # Compute confusion matrix\n",
    "class_names = list(test_generator.class_indices.keys())  # Get class names\n",
    "plot_confusion_matrix(cm, class_names)\n",
    "print(classification_report(y_true, y_pred_classes, target_names=class_names))  # Print classification report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22615e2-9ee4-483a-9fcb-ee5f1522cead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot ROC curve\n",
    "def plot_roc_curve(y_true, y_pred):\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)  # Compute ROC curve\n",
    "    roc_auc = auc(fpr, tpr)  # Compute AUC\n",
    "\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)  # Plot ROC curve\n",
    "    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')  # Plot diagonal line\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.savefig('roc_curve.png')  # Save as image\n",
    "    plt.show()\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "y_true_binary = pd.get_dummies(y_true).values  # Convert true labels to binary format\n",
    "y_pred_prob = model.predict(test_generator)  # Get predicted probabilities\n",
    "for i in range(len(class_names)):\n",
    "    plot_roc_curve(y_true_binary[:, i], y_pred_prob[:, i])  # Plot ROC curve for each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce9298a2-2660-4c2a-9d3d-139511469119",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Directory for unseen data\n",
    "unseen_data_dir = \"unseen_data\"\n",
    "unseen_images = [os.path.join(unseen_data_dir, img) for img in os.listdir(unseen_data_dir) if img.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Image preprocessing function\n",
    "def preprocess_image(image_path, target_size=(224, 224)):\n",
    "    img = load_img(image_path, target_size=target_size)  # Load the image\n",
    "    img_array = img_to_array(img)  # Convert image to array\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # Expand dimensions to fit model input\n",
    "    img_array /= 255.0  # Normalize the image\n",
    "    return img_array\n",
    "\n",
    "# Function to visualize classification results\n",
    "def visualize_predictions(image_paths, model, class_labels):\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    num_images = len(image_paths)\n",
    "    num_images_per_row = 5\n",
    "    num_rows = np.ceil(num_images / num_images_per_row).astype(int)\n",
    "    \n",
    "    for i, image_path in enumerate(image_paths):\n",
    "        img_array = preprocess_image(image_path)\n",
    "        prediction = model.predict(img_array)  # Predict the class\n",
    "        predicted_class = class_labels[np.argmax(prediction)]  # Get the predicted class label\n",
    "        \n",
    "        plt.subplot(num_rows, num_images_per_row, i + 1)\n",
    "        img = load_img(image_path)  # Load the image for visualization\n",
    "        plt.imshow(img)\n",
    "        plt.title(f'Predicted: {predicted_class}')  # Set the title as predicted class\n",
    "        plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('unseen_data_predictions.png')  # Save as image\n",
    "    plt.show()\n",
    "\n",
    "# Define class labels\n",
    "class_labels = ['black bear', 'newfoundland']\n",
    "\n",
    "# Visualize classification results on the unseen dataset\n",
    "visualize_predictions(unseen_images, model, class_labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aacaffc6-997b-49d9-8cd7-5bec344d51a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the model structure\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Save the model structure to a file named 'model_structure.png'\n",
    "plot_model(model, to_file='model_structure.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Import the Image display function from IPython\n",
    "from IPython.display import Image\n",
    "\n",
    "# Display the saved model structure image\n",
    "Image(filename='model_structure.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
